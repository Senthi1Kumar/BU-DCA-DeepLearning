{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisIsNSK/BU-DCA-DeepLearning/blob/main/Framework_Test_CatsVsDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjXKhkEKrwEM"
      },
      "outputs": [],
      "source": [
        "DIR_PATH = \"/content/drive/MyDrive/deep_learning/CatsVsDogs_Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNFGomY8FpfO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KCCoZULytKc",
        "outputId": "567da1f4-9608-40d1-96b0-f5ff5d24c88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBe2As5MILop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d9b638-bcbc-4ebf-f596-6bba2c3c0767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDba1FCaF-z5"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"/content/gdrive/MyDrive/CatsVsDogs_Dataset/\"\n",
        "\n",
        "train_dir = ROOT_DIR + \"train\"\n",
        "validation_dir = ROOT_DIR + \"validation\"\n",
        "\n",
        "## Train\n",
        "train_class1_dir = ROOT_DIR + \"train/Cat\"\n",
        "train_class2_dir = ROOT_DIR + \"train/Dog\"\n",
        "\n",
        "\n",
        "## Validation\n",
        "validation_class1_dir = ROOT_DIR + \"validation/Cat\"\n",
        "validation_class2_dir = ROOT_DIR + \"validation/Dog\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XeTH4yiQG4qf",
        "outputId": "463e6fa4-b840-4f43-97d7-f6296caad857"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e6eff5661050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_class1_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_class1_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_class2_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_class2_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_class1_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_class1_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/CatsVsDogs_Dataset/train/Cat'"
          ]
        }
      ],
      "source": [
        "num_class1_tr = len(os.listdir(train_class1_dir))\n",
        "num_class2_tr = len(os.listdir(train_class2_dir))\n",
        "\n",
        "\n",
        "num_class1_val = len(os.listdir(validation_class1_dir))\n",
        "num_class2_val = len(os.listdir(validation_class2_dir))\n",
        "\n",
        "\n",
        "total_train = num_class1_tr + num_class2_tr \n",
        "total_val = num_class1_val + num_class2_val\n",
        "\n",
        "print('Total training Class-1 images:', num_class1_tr)\n",
        "print('Total training Class-2 images:', num_class2_tr)\n",
        "\n",
        "\n",
        "print(\"--\")\n",
        "print('Total validation Class-1 images:', num_class1_val)\n",
        "print('Total validation Class-2 images:', num_class2_val)\n",
        "\n",
        "\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yLa0bvpI8Ui"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 10  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 100  # Our training data consists of images with width of 150 pixels and height of 150 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJl0aLfhI_c3"
      },
      "outputs": [],
      "source": [
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
        "'''\n",
        ", featurewise_std_normalization=True,\n",
        "samplewise_std_normalization=True,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True,\n",
        "#brightness_range=(0.0,0.25),\n",
        "rotation_range=45)  # Generator for our validation data\n",
        "\n",
        "test_image_generator_1     = ImageDataGenerator(rescale=1./255, featurewise_std_normalization=True,\n",
        "samplewise_std_normalization=True,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True,\n",
        "#brightness_range=(0.0,0.25),\n",
        "rotation_range=45)  # Generator for our validation data\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"After defining our generators for training and validation images, **flow_from_directory** method will load images from the disk, apply rescaling, and resize them using single line of code.\"\"\"\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "#test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                         #directory=test_dir,\n",
        "                                                         #shuffle=True,\n",
        "                                                         #target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                         #class_mode='binary')\n",
        "#test_data_gen_1 = test_image_generator_1.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                         #directory=test_dir_1,\n",
        "                                                         #shuffle=True,\n",
        "                                                         #target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                         #class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTsTI1-hJB15",
        "outputId": "e93c64b1-a270-4a8e-d584-4e78b8843924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-562e869831c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_training_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\"\"\"The `next` function returns a batch from the dataset. One batch is a tuple of (*many images*, *many labels*). For right now, we're discarding the labels because we just want to look at the images.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_gen' is not defined"
          ]
        }
      ],
      "source": [
        "sample_training_images, _ = next(train_data_gen)\n",
        "\n",
        "\"\"\"The `next` function returns a batch from the dataset. One batch is a tuple of (*many images*, *many labels*). For right now, we're discarding the labels because we just want to look at the images.\"\"\"\n",
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImages(sample_training_images[:5])  # Plot images 0-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gIYBrwjKDf4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),  ### 128 -> 256??\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),  ### 128 -> 256??\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFqiO_qxKJtv"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkvdHaPHKNQn"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkXX6DrrKP3o"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))),\n",
        "    #callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2VM5Kc2TQ8h"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILvvDIihUFGf"
      },
      "outputs": [],
      "source": [
        "## Getting the True Labels\n",
        "\n",
        "val_image_batch, val_label_batch = next(iter(val_data_gen))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "#print(\"Validation batch shape:\", val_image_batch.shape)\n",
        "true_label_ids\n",
        "val_label_batch[0]\n",
        "#true_label_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHy9R7WwTcvH"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Prediction - Validation & Result Ploting\n",
        "\n",
        "tf_model_predictions = model.predict(val_image_batch)\n",
        "print(\"Prediction results shape:\", tf_model_predictions.shape)\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range((len(tf_model_predictions))):\n",
        "  plt.subplot(7,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if np.argmax(tf_model_predictions[n]) == val_label_batch[n] else \"red\"\n",
        "  plt.title(str(np.argmax(tf_model_predictions[n])) + \"/\" + str(val_label_batch[n]), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect) \\n Label: Predicted/Actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKxILZy9VCx4"
      },
      "outputs": [],
      "source": [
        "## Getting the True Labels\n",
        "\n",
        "val_image_batch, val_label_batch = next(iter(val_data_gen))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "#print(\"Validation batch shape:\", val_image_batch.shape)\n",
        "true_label_ids\n",
        "val_label_batch\n",
        "#true_label_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHrUb2WQVMK4"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Prediction - Validation & Result Ploting\n",
        "for i in range (total_val//BATCH_SIZE):\n",
        "  val_image_batch, val_label_batch = next(iter(val_data_gen))\n",
        "  tf_model_predictions = model.predict(val_image_batch)\n",
        "  print(\"Prediction results shape:\", tf_model_predictions.shape)\n",
        "  plt.figure(figsize=(10,9))\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "  for n in range((len(tf_model_predictions))):\n",
        "    plt.subplot(7,5,n+1)\n",
        "    plt.imshow(val_image_batch[n])\n",
        "    color = \"green\" if np.argmax(tf_model_predictions[n]) == val_label_batch[n] else \"red\"\n",
        "    plt.title(str(np.argmax(tf_model_predictions[n])) + \"/\" + str(int(val_label_batch[n])), color=color)\n",
        "    plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect) \\n Label: Predicted/Actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZDB4ujfUxtD"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJYQMGAKSvH1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCJ4EChuVaNK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}